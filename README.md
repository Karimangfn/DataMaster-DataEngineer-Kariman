# Data Master - Kariman Gomes

<p align="center">
  <img src="assets/images/Data-Master-Logo.png" style="width:800px; height:250px;">
</p>

O reposit√≥rio "DataMaster-DataEngineer-Kariman" apresenta a solu√ß√£o de Engenharia de Dados criada por [Kariman](https://www.linkedin.com/in/kariman-gomes/) como parte do programa Data Master, uma iniciativa da F1rst Santander. <p>

## üìë Sum√°rio

1. üìå [Vis√£o Geral do Projeto](#-1-vis√£o-geral-do-projeto)

   * [Prop√≥sito](#11-prop√≥sito)
   * [Abordagem](#12-abordagem)

2. üèóÔ∏è [Arquitetura de Solu√ß√£o](#%EF%B8%8F-2-arquitetura-de-solu√ß√£o)

   * [Vis√£o Geral](#21-vis√£o-geral)
   * [Diagrama da Arquitetura de Solu√ß√£o](#22-diagrama-da-arquitetura-de-solu√ß√£o)
   * [Componentes Principais](#23-componentes-principais)

3. ‚öôÔ∏è [Arquitetura T√©cnica](#%EF%B8%8F-3-arquitetura-t√©cnica)

   * [Descri√ß√£o do Fluxo de Dados](#31-descri√ß√£o-do-fluxo-de-dados)
   * [Tecnologias e Servi√ßos Utilizados](#32-tecnologias-e-servi√ßos-utilizados)
   * [Infraestrutura como C√≥digo (IaC)](#33-infraestrutura-como-c√≥digo)
   * [GitHub Actions](#34-github-actions)
   * [Orquestra√ß√£o de Pipelines](#35-orquestra√ß√£o-de-pipelines)
   * [Extra√ß√£o e Ingest√£o de Dados](#36-extra√ß√£o-e-ingest√£o-de-dados)
   * [Armazenamento de Dados](#37-armazenamento-de-dados)
   * [Processamento e Transforma√ß√£o dos Dados](#38-processamento-e-transforma√ß√£o-dos-dados)
   * [Qualidade e Valida√ß√£o de Dados](#39-qualidade-e-valida√ß√£o-de-dados)
   * [Mascaramento e Seguran√ßa dos Dados](#310-mascaramento-e-seguran√ßa-dos-dados)
   * [Governan√ßa](#311-governan√ßa)
   * [Observabilidade e Monitoramento](#312-observabilidade-e-monitoramento)
   * [Escalabilidade e Desempenho](#313-escalabilidade-e-desempenho)
   * [Metodologia de Desenvolvimento](#314-metodologia-de-desenvolvimento)

4. üöÄ [Guia de Configura√ß√£o e Execu√ß√£o](#-4-guia-de-configura√ß√£o-e-execu√ß√£o)

   * [Pr√©-requisitos](#41-pr√©-requisitos)
   * [Cria√ß√£o do Reposit√≥rio a partir do Template](#42-cria√ß√£o-do-reposit√≥rio-a-partir-do-template)
   * [Configura√ß√£o das Secrets e Vari√°veis de Ambiente](#43-configura√ß√£o-das-secrets-e-vari√°veis-de-ambiente)
   * [Provisionamento da Infraestrutura na Azure](#44-provisionamento-da-infraestrutura-na-azure)
   * [Build e Publica√ß√£o das Imagens Docker](#45-build-e-publica√ß√£o-das-imagens-docker)
   * [Deploy dos Microservi√ßos no AKS](#46-deploy-dos-microservi√ßos-no-aks)
   * [Execu√ß√£o do Pipeline de Dados](#47-execu√ß√£o-do-pipeline-de-dados)

5. üí° [Melhorias e Considera√ß√µes Finais](#-5-melhorias-e-considera√ß√µes-finais)

   * [Melhorias Futuras](#51-melhorias-futuras)
   * [Considera√ß√µes Finais](#52-considera√ß√µes-finais)

6. üìö [Refer√™ncias](#-6-refer√™ncias)

---

## üìå 1. Vis√£o Geral do Projeto

Este projeto consiste em uma **plataforma de engenharia e experimenta√ß√£o de dados** desenvolvida para demonstrar, em um ambiente controlado e reproduz√≠vel, as principais pr√°ticas de **ingest√£o, processamento, governan√ßa e automa√ß√£o de dados em nuvem**.

A solu√ß√£o foi concebida como uma **infraestrutura completa**, que une conceitos de **engenharia de dados**, **engenharia de software** e **arquitetura em nuvem** para sustentar fluxos de dados **escal√°veis, audit√°veis e seguros**.

### 1.1 Prop√≥sito

A plataforma busca resolver um conjunto mais amplo de desafios enfrentados em ambientes de dados modernos, incluindo:

* Fragmenta√ß√£o de dados em m√∫ltiplas origens e formatos.
* Falta de padroniza√ß√£o e governan√ßa no ciclo de vida dos dados.
* Dificuldade de reprodutibilidade e versionamento de ambientes.
* Baixa automa√ß√£o nos processos de ingest√£o, transforma√ß√£o e deploy.
* Necessidade de garantir seguran√ßa, qualidade e rastreabilidade ponta a ponta.

### 1.2 Abordagem

A solu√ß√£o foi projetada para atender a esses desafios de forma **modular e integrada**, combinando:

* **Arquitetura Medalh√£o (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold)** para organizar e evoluir os dados em camadas de qualidade.
* **Infraestrutura como C√≥digo (Terraform)** para provisionar automaticamente os recursos na Azure.
* **Microservi√ßos de Ingest√£o** para integrar m√∫ltiplas fontes de dados de forma independente e escal√°vel.
* **Databricks e Delta Lake** para processamento distribu√≠do, versionamento e confiabilidade transacional.
* **Automa√ß√£o com GitHub Actions** para CI/CD de infraestrutura, c√≥digo e pipelines.
* **Governan√ßa e Seguran√ßa** via RBAC, Service Principals e mascaramento de dados sens√≠veis.
* **Observabilidade e Monitoramento** para acompanhamento de execu√ß√µes e detec√ß√£o de falhas.
* **Boas pr√°ticas de Engenharia de Software**, como Clean Architecture, testes automatizados e valida√ß√µes de qualidade de c√≥digo.

---

##  üèóÔ∏è 2. Arquitetura de Solu√ß√£o

### 2.1 Vis√£o Geral

A arquitetura foi projetada para sustentar uma plataforma modular de engenharia de dados, capaz de integrar, processar e disponibilizar informa√ß√µes de forma escal√°vel e governada na nuvem.

No centro da solu√ß√£o, encontra-se um pipeline de dados estruturado na arquitetura medalh√£o (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold), respons√°vel por orquestrar o fluxo de dados desde a ingest√£o at√© a camada anal√≠tica. Esse pipeline √© suportado por uma infraestrutura automatizada e reprodut√≠vel, provisionada via Terraform, e integrada a componentes de observabilidade, seguran√ßa e automa√ß√£o cont√≠nua.

Os dados s√£o ingeridos de tr√™s origens distintas (banco de dados, API e arquivos) por meio de microservi√ßos independentes, processados no Databricks e armazenados em um Data Lake na Azure.

### 2.2 Diagrama da Arquitetura de Solu√ß√£o

![Figura 1 ‚Äî Arquitetura de Solu√ß√£o](assets/images/Arquitetura-Pipeline-de-Dados.png)

*Figura 1 ‚Äî Arquitetura de solu√ß√£o em alto n√≠vel, mostrando ingest√£o, processamento e armazenamento das camadas do Data Lake.*

### 2.3 Componentes Principais

- **Microservi√ßos de Ingest√£o**: Cada microservi√ßo √© respons√°vel por extrair dados de uma fonte espec√≠fica e grav√°-los na camada raw do Data Lake.
- **Data Lake (Azure Storage Account)**: Armazena os dados em diferentes camadas de processamento (Raw, Bronze, Silver e Gold), seguindo a arquitetura medalh√£o e permitindo rastreabilidade.
- **Databricks**: realiza o processamento e a transforma√ß√£o dos dados. A camada Bronze utiliza o Auto Loader para ingest√£o automatizada, a camada Silver aplica limpeza, padroniza√ß√£o e mascaramento de dados, e a camada Gold gera a tabela pronta para an√°lise.
- **Infraestrutura como C√≥digo (Terraform)**: Provisiona todos os recursos necess√°rios, incluindo ACR, AKS, Storage Account, Databricks e demais componentes da arquitetura.
- **Automa√ß√£o (GitHub Actions)**: Gerencia a cria√ß√£o, o deploy dos microservi√ßos e verifica√ß√£o de qualidade de c√≥digo.

---

## ‚öôÔ∏è 3. Arquitetura T√©cnica

### 3.1 Descri√ß√£o do Fluxo de Dados

1. **Ingest√£o**: Os microservi√ßos consomem dados das fontes (Banco de Dados, API, Arquivos) e gravam na camada raw do Data Lake. 
2. **Bronze**: Databricks l√™ os dados da raw e cria a tabela Delta, mantendo a integridade das informa√ß√µes.
3. **Silver**: Aplica transforma√ß√µes de limpeza, padroniza√ß√£o e mascaramento de dados sens√≠veis.  
4. **Gold**: Gera tabelas prontas para consumo ou an√°lises.

### 3.2 Tecnologias e Servi√ßos Utilizados

- **Resource Group**: Agrupa todos os recursos provisionados na Azure. 
- **ACR (Azure Container Service)**: Reposit√≥rio para armazenar e versionar as imagens Docker dos microservi√ßos.  
- **AKS (Azure Kubernetes Service)**: Execu√ß√£o dos microservi√ßos de ingest√£o.
- **Storage Account**: Armazenamento do Data Lake com camadas Raw, Bronze, Silver e Gold.
- **Databricks**: Processamento e transforma√ß√£o dos dados.
- **Delta Lake**: Garantia de consist√™ncia, versionamento e ACID nas tabelas.
- **Terraform**: Provisionamento de toda a infraestrutura na Azure.
- **GitHub Actions**: Automa√ß√£o de cria√ß√£o de infraestrutura, deploy de microservi√ßos e execu√ß√£o de jobs.

### 3.3 Infraestrutura como C√≥digo

![Figura 2 ‚Äî Infraestrutura CI/CD](assets/images/Arquitetura-Infrastructure-CI-CD.png)  

*Figura 2 ‚Äî Arquitetura de infraestrutura com Terraform e principais recursos provisionados na Azure.*

Toda a infraestrutura do projeto √© criada com uso de **Terraform**, que tamb√©m salva o estado das cria√ß√µes em artefatos para garantir a consist√™ncia do ambiente e a persist√™ncia do estado entre execu√ß√µes, evitando perdas ou diverg√™ncias durante atualiza√ß√µes.

### Valida√ß√µes (CI)
- **Check Github Token**: Antes da cria√ß√£o dos recursos, √© verificado se o *Personal Access Token* do GitHub est√° criado e configurado com os acessos necess√°rios.

- **Check Azure Role Assignments**: Valida se o *Service Principal* necess√°rio para a cria√ß√£o dos recursos est√° configurado corretamente com as permiss√µes adequadas para atribuir acesso a outro recursos.

- **check Azure Group Permissions**: Valida se o *Service Principal* necess√°rio para a cria√ß√£o dos recursos est√° configurado corretamente com as permiss√µes adequadas para criar grupos na Azure.

### Cria√ß√£o de Recursos (CD)
- **Resource Group**: Respons√°vel por armazenar os recursos.  
- **Azure Container Registry (ACR)**: Armazena as imagens dos microservi√ßos.  
- **Azure Kubernetes Service (AKS)**: Cluster respons√°vel pela execu√ß√£o dos microservi√ßos.
  - Cria√ß√£o de **role assignment** para permitir que o AKS fa√ßa pull das imagens.  
- **Storage Account**: Armazenamento das tabelas de dados.
  - Cria√ß√£o de **role assignment** do Service Principal com permiss√£o de Storage Blob Data Contributor.
- **Storage Containers**: Containers espec√≠ficos para as camadas de dados Raw, Bronze, Silver e Gold.  
- **Databricks**: Cria√ß√£o de recursos e configura√ß√£o do workspace, incluindo:
  - Workspace Databricks
  - Conector de acesso (Access Connector)
  - Cria√ß√£o de External Locations (Bronze, Silver, Gold)
  - Cria√ß√£o de Schema
  - Cria√ß√£o de Job de processamento
  - Cria√ß√£o de Grupos de acesso na workspace
- **Access Groups**: Cria√ß√£o de grupos de acesso para governan√ßa na Azure.

#### Estrutura

```bash
infrastructure/
‚îú‚îÄ‚îÄ main.tf              # Chama os m√≥dulos e define os recursos principais
‚îú‚îÄ‚îÄ variables.tf         # Vari√°veis globais usadas pelos m√≥dulos
‚îú‚îÄ‚îÄ outputs.tf           # Sa√≠das de recursos criados
‚îú‚îÄ‚îÄ providers.tf         # Providers (Azure, Databricks, etc.)
‚îî‚îÄ‚îÄ modules/             # M√≥dulos reutiliz√°veis
    ‚îú‚îÄ‚îÄ access/          # Grupos e permiss√µes (Azure AD / IAM)
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îú‚îÄ‚îÄ acr/             # Azure Container Registry
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
    ‚îú‚îÄ‚îÄ aks/             # Azure Kubernetes Service
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
    ‚îú‚îÄ‚îÄ databricks/      # Databricks workspace
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ providers.tf
    ‚îú‚îÄ‚îÄ resource_group/  # Resource Group
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
    ‚îî‚îÄ‚îÄ storage/         # Storage Account e containers
        ‚îú‚îÄ‚îÄ main.tf
        ‚îú‚îÄ‚îÄ variables.tf
        ‚îî‚îÄ‚îÄ outputs.tf
        ‚îî‚îÄ‚îÄ providers.tf
```

### 3.4 GitHub Actions

O GitHub Actions √© respons√°vel por orquestrar e automatizar todas as etapas do projeto, incluindo:

- **Provisionamento de Infraestrutura**: executa o Terraform para cria√ß√£o e atualiza√ß√£o de recursos na Azure.
- **Orquestra√ß√£o de Pipeline**: coordena a execu√ß√£o de todos os passos, incluindo o disparo dos microservi√ßos de ingest√£o no AKS e dos jobs de transforma√ß√£o no Databricks.
- **Deploy de Microservi√ßos**: build e publica√ß√£o de imagens Docker no ACR, seguido de deploy no AKS.  
- **Transforma√ß√£o de Dados**: integra√ß√£o com Databricks para execu√ß√£o dos pipelines de Bronze, Silver e Gold. 

#### Resumo de Execu√ß√£o (Summary)
Cada execu√ß√£o de workflow gera automaticamente um **summary** dentro do GitHub Actions, contendo:  
- Recursos criados/atualizados ou implantados de acordo com o tipo de workflow.
- Status de execu√ß√£o das etapas (Infra, Ingest√£o, Transforma√ß√£o).

   ![Figura 4.2 ‚Äî Infra](assets/images/config-execution/infra-04-02.png)

#### Fluxo dos Workflows

**A. Workflows Principais**
1. **Infraestrutura** ‚Üí Provisionamento completo via Terraform  
   1.1 - Deploy Cloud Infrastructure  
2. **Setup de Ingest√£o** ‚Üí Setup de Microservi√ßos no ACR e AKS  
   2.1 - Build and Push to ACR  
   2.2 - AKS Setup and Deploy  
3. **Orquestra√ß√£o** ‚Üí Execu√ß√£o dos Microservi√ßos e Job no Databricks  
   3.1 - Orchestrate Data Pipeline  

**B. Workflows de Qualidade (Pull Requests)**  
1. **Valida√ß√£o de Microservi√ßo** ‚Üí Executa lint, pr√©-commit hooks e testes para os microservi√ßos.
  1.1 - Microservice Quality
2. **Valida√ß√£o de Data Processing** ‚Üí Executa lint, pr√©-commit hooks e testes para o job de Data Processing.
  2.1 - Data Processing Quality

### 3.5 Orquestra√ß√£o de Pipelines

A orquestra√ß√£o dos pipelines √© realizada por um **workflow do GitHub Actions**, que atua como coordenador central da execu√ß√£o de todo o processo de dados. O workflow realiza as seguintes fun√ß√µes:

- Detecta os microservi√ßos que precisam ser executados, lendo arquivos de vers√£o nos reposit√≥rios.
- Dispara os **jobs de ingest√£o no AKS**, validando previamente a exist√™ncia das imagens no ACR.
- Dispara o **job de transforma√ß√£o no Databricks**, garantindo a execu√ß√£o dos pipelines Bronze, Silver e Gold.
- Coleta os resultados das execu√ß√µes, tanto do AKS quanto do Databricks, e gera um resumo consolidado da execu√ß√£o.

   ![Figura 1 ‚Äî New Pipeline](assets/images/config-execution/pipeline-new.png)

### 3.6 Extra√ß√£o e Ingest√£o de Dados

![Figura 3 ‚Äî Microservi√ßos de Ingest√£o](assets/images/Arquitetura-Microservices-CI-CD.png)

*Figura 3 ‚Äî Arquitetura de CI/CD dos microservi√ßos de ingest√£o: extra√ß√£o de dados, build, deploy no AKS.*

A ingest√£o dos dados √© realizada por **microservi√ßos** desenvolvidos para cada fonte de dados (Banco de Dados, API e Arquivos). Esses microservi√ßos s√£o empacotados em cont√™ineres e executados em um **Azure Kubernetes Service (AKS)**.

O fluxo segue os seguintes passos:  
1. Cada microservi√ßo se conecta √† sua respectiva fonte.  
2. Os dados s√£o extra√≠dos no formato de origem (JSON ou CSV).  
3. Os microservi√ßos gravam os dados diretamente na **camada Raw** do Data Lake, em pastas espec√≠ficos.  

Caracter√≠sticas principais:
- **Independ√™ncia**: Cada microservi√ßo √© respons√°vel por uma fonte, facilitando manuten√ß√£o e evolu√ß√£o.  
- **Padroniza√ß√£o**: Apesar das diferentes origens, os dados seguem o mesmo schema.  
- **Escalabilidade**: O uso do AKS permite aumentar ou reduzir r√©plicas de ingest√£o conforme a demanda.  
- **Automa√ß√£o**: Pipelines no GitHub Actions garantem que os microservi√ßos sejam validados, constru√≠dos e implantados automaticamente no cluster.

#### Estrutura

```bash
microservice_name/
‚îú‚îÄ‚îÄ helm/               # Helm chart para deploy no AKS
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ application/      # Regras de neg√≥cio da aplica√ß√£o
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ helpers/        # Fun√ß√µes utilit√°rias
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ services/       # Servi√ßos de orquestra√ß√£o da l√≥gica
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ validators/     # Valida√ß√µes de entrada e regras espec√≠ficas
‚îÇ ‚îú‚îÄ‚îÄ domain/           # Defini√ß√µes de dom√≠nio
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ exceptions/     # Classes de exce√ß√µes espec√≠ficas
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ ports/          # Interfaces para comunica√ß√£o entre camadas
‚îÇ ‚îú‚îÄ‚îÄ infrastructure/   # Implementa√ß√µes concretas
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ authentication/ # Autentica√ß√£o e seguran√ßa
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config/         # Configura√ß√µes de ambiente
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ logging/        # Logs e monitoramento
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ingestion/      # Conectores e ingest√£o de dados
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ storage/        # Intera√ß√£o com o Data Lake
‚îÇ ‚îî‚îÄ‚îÄ interfaces/       # Pontos de entrada
‚îÇ ‚îî‚îÄ‚îÄ main.py           # API/CLI principal do microservi√ßo
‚îú‚îÄ‚îÄ tests/              # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ Dockerfile          # Defini√ß√£o da imagem Docker
‚îú‚îÄ‚îÄ Makefile            # Defini√ß√£o da imagem Docker
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias do servi√ßo
‚îú‚îÄ‚îÄ setup.py            # Defini√ß√£o da imagem Docker
‚îî‚îÄ‚îÄ VERSION             # Usado para versionamento do Microservi√ßo
```

A organiza√ß√£o segue princ√≠pios da Clean Architecture, garantindo separa√ß√£o de responsabilidades e facilidade de manuten√ß√£o:
- **domain** ‚Üí Regras de neg√≥cio puras, interfaces (ports) e exce√ß√µes.
- **application** ‚Üí Casos de uso, servi√ßos, validadores e helpers.
- **infrastructure** ‚Üí Autentica√ß√£o, logging, ingest√£o e persist√™ncia.
- **interfaces** ‚Üí Pontos de entrada do servi√ßo (ex.: main.py).
- **tests** ‚Üí Testes unit√°rios e de integra√ß√£o.
- **helm** ‚Üí Manifests para deploy no AKS.

Arquivos de Configura√ß√£o:
- **.dockerignore** -> Exclui arquivos desnecess√°rios no build Docker.  
- **.flake8** -> Regras de lint para garantir padr√£o de c√≥digo. 
- **.gitignore** -> Define arquivos ignorados no versionamento.
- **.pre-commit-config.yaml** -> Hooks para valida√ß√µes autom√°ticas antes do commit.
- **pytest.ini** -> Configura√ß√µes para execu√ß√£o dos testes com Pytest.

### 3.7 Armazenamento de Dados

O armazenamento dos dados √© realizado em uma **Azure Storage Account**, estruturada segundo a arquitetura medalh√£o.
Cada camada possui um **container dedicado**, garantindo organiza√ß√£o e isolamento entre os est√°gios do pipeline:

- **Raw**: Camada onde os microservi√ßos depositam os dados ingeridos, preservando-os no formato original.  
- **Bronze**: Camada onde o Databricks cria tabelas Delta a partir da Raw, garantindo rastreabilidade e hist√≥rico.  
- **Silver**: Camada que cont√©m dados limpos, padronizados e com mascaramento de informa√ß√µes sens√≠veis.  
- **Gold**: Camada final com dados prontos para consumo em an√°lises e dashboards. 

### 3.8 Processamento e Transforma√ß√£o dos Dados

![Figura 4 ‚Äî Data Processing CI](assets/images/Arquitetura-Data-Processing-CI.png)

*Figura 4 ‚Äî Arquitetura de processamento e transforma√ß√£o de dados em Databricks, seguindo a arquitetura medalh√£o.*

O processamento dos dados √© realizado no **Databricks**, utilizando **Microservi√ßos Python** organizados em tarefas dentro de um **Job**.
Cada job √© dividido em tr√™s etapas principais, alinhadas √† arquitetura medalh√£o:

1. **Bronze**  
   - Leitura dos dados da camada Raw por meio do **Auto Loader** do Databricks.  
   - Cria√ß√£o de tabela **Delta**, preservando os dados ingeridos com hist√≥rico e versionamento.
   - Registro de metadados de rastreabilidade: source_file_name, ingestion_timestamp e raw_ingestion_id (UUID √∫nico por execu√ß√£o).
   - Aplica√ß√£o de controle de acesso garantindo permiss√µes adequadas a grupos de usu√°rios.

  > üí° O processamento incremental √© realizado com o **Auto Loader**, que detecta novos arquivos na camada Raw e processa apenas dados novos.

2. **Silver**  
   - Aplica√ß√£o de regras de **limpeza e padroniza√ß√£o** (ex.: normaliza√ß√£o de formatos, remo√ß√£o de inconsist√™ncias).  
   - Deduplica√ß√£o baseada em customer_id e purchase_date, preservando o registro mais recente.
   - Mascaramento de informa√ß√µes sens√≠veis:
      - cpf ‚Üí SHA-256 ‚Üí coluna cpf_masked
      - credit_card_number ‚Üí SHA-256 ‚Üí coluna credit_card_masked
      - email ‚Üí ofusca√ß√£o parcial mantendo dom√≠nio
   - Enriquecimento dos dados, como a coluna high_value_purchase (flag de compras de alto valor).
   - Preserva√ß√£o das colunas de metadados da Bronze (source_file_name, ingestion_timestamp, raw_ingestion_id).
   - Aplica√ß√£o de controle de acesso garantindo permiss√µes adequadas a grupos de usu√°rios.

3. **Gold**  
   - Agrega√ß√£o dos dados Silver em tabelas anal√≠ticas, prontas para consumo em BI.
   - Cria√ß√£o da coluna derivada purchase_month (formato yyyy-MM) para an√°lises mensais.
   - C√°lculo de m√©tricas agregadas por store_location e purchase_month:
      - total_purchases ‚Üí n√∫mero de compras
      - total_revenue ‚Üí soma do valor total
      - average_purchase_value ‚Üí valor m√©dio de compra
      - high_value_purchases ‚Üí contagem de compras de alto valor
   - Aplica√ß√£o de controle de acesso garantindo permiss√µes adequadas a grupos de usu√°rios.

#### Estrutura

```bash
processing_job/  
‚îú‚îÄ‚îÄ src/  
‚îÇ   ‚îú‚îÄ‚îÄ config/       # Configura√ß√µes do pipeline (par√¢metros, schemas, paths)  
‚îÇ   ‚îú‚îÄ‚îÄ modules/      # M√≥dulos principais de transforma√ß√£o (Bronze, Silver ou Gold)  
‚îÇ   ‚îú‚îÄ‚îÄ utils/        # Fun√ß√µes utilit√°rias reutiliz√°veis  
‚îÇ   ‚îî‚îÄ‚îÄ main.py       # Script principal do job executado no Databricks  
‚îú‚îÄ‚îÄ tests/            # Testes unit√°rios e de integra√ß√£o  
‚îú‚îÄ‚îÄ requirements.txt  # Depend√™ncias do job
```

Arquivos de Configura√ß√£o
- **.flake8** ‚Üí Regras de lint para garantir padr√£o de c√≥digo.
- **.gitignore** ‚Üí Define arquivos ignorados no versionamento.
- **.pre-commit-config.yaml** ‚Üí Hooks para valida√ß√µes autom√°ticas antes do commit.  
- **pytest.ini** ‚Üí Configura√ß√µes para execu√ß√£o dos testes com Pytest.

### 3.9 Qualidade e Valida√ß√£o de Dados

A qualidade dos dados √© garantida a partir da camada **Silver**, onde s√£o aplicadas regras de valida√ß√£o e consist√™ncia antes de disponibilizar as informa√ß√µes para consumo. O processo combina verifica√ß√µes automatizadas e padroniza√ß√µes implementadas nos microservi√ßos do Databricks.

Principais valida√ß√µes aplicadas:  
- **Integridade de schema**: checagem se os dados seguem o schema esperado.  
- **Valores obrigat√≥rios**: verifica√ß√£o de colunas cr√≠ticas que n√£o podem estar nulas (`customer_id`, `cpf`).
- **Convers√£o de tipos**: purchase_date ‚Üí DateType, total_amount ‚Üí DoubleType.
- **Formatos v√°lidos**: confer√™ncia de padr√µes, como CPF v√°lido ou formato correto de e-mail.
- **Deduplica√ß√£o**: remo√ß√£o de registros duplicados mantendo o mais recente por customer_id e purchase_date.
- **Valida√ß√£o de formatos**: emails v√°lidos, datas consistentes, valores num√©ricos coerentes.
- **Valores de dom√≠nio**: confer√™ncia de atributos contra listas pr√©-definidas (ex.: store_location). 

Ferramentas e pr√°ticas:
- Delta Lake ‚Üí versionamento, hist√≥rico, rollback e rastreabilidade.
- Microservi√ßos Python no Databricks ‚Üí implementam todas as valida√ß√µes, limpeza, deduplica√ß√£o e mascaramento.   

**Benef√≠cios principais**:  
- Evita propaga√ß√£o de dados inconsistentes para as camadas anal√≠ticas.  
- Garante confiabilidade e consist√™ncia para relat√≥rios e dashboards.  
- Facilita auditoria e rastreabilidade em caso de erros de ingest√£o ou transforma√ß√£o.

### 3.10 Mascaramento e Seguran√ßa dos Dados

O projeto adota pr√°ticas de **seguran√ßa e privacidade** para proteger informa√ß√µes sens√≠veis dos clientes durante o ciclo de vida dos dados.  
O foco principal est√° no **mascaramento de dados pessoais**, realizado na transi√ß√£o da camada **Bronze ‚Üí Silver**.

#### Mascaramento de Dados
- **CPF**: aplica√ß√£o de hash criptogr√°fico (SHA-256), preservando apenas parte para rastreabilidade.
- **N√∫mero de cart√£o de cr√©dito**: aplica√ß√£o de hash criptogr√°fico (SHA-256), garantindo que os dados originais n√£o sejam expostos. 

Essas transforma√ß√µes s√£o aplicadas atrav√©s dos **Microservi√ßos Python**, garantindo que os dados sens√≠veis n√£o avancem para a camada Gold.

#### Seguran√ßa de Armazenamento e Acesso
- **Azure Storage Account**: Controle de permiss√µes via *role-based access control* (RBAC).  
- **Segrega√ß√£o por camadas**: Cada container (Raw, Bronze, Silver, Gold) possui pol√≠ticas de acesso espec√≠ficas.  
- **GitHub Actions**: Uso de *secrets* para armazenar credenciais de forma segura.  
- **Service Principals**: Autentica√ß√£o entre servi√ßos com permiss√µes m√≠nimas necess√°rias.  

**Benef√≠cios principais**:  
- Prote√ß√£o de informa√ß√µes sens√≠veis em conformidade com boas pr√°ticas de governan√ßa.  
- Redu√ß√£o de riscos em auditorias e conformidade regulat√≥ria (LGPD).  
- Garantia de que dados anal√≠ticos n√£o exponham informa√ß√µes pessoais desnecess√°rias.

### 3.11 Governan√ßa

Nesse projeto, o tema de governan√ßa de dados √© tratado para garantir que cada usu√°rio tenha acesso apenas √†s informa√ß√µes necess√°rias, de acordo com sua fun√ß√£o, promovendo seguran√ßa, rastreabilidade e compliance.

| Persona             | N√≠vel de Acesso                   | Objetivo do Acesso                                              |
|---------------------|-----------------------------------|-----------------------------------------------------------------|
| Engenheiro de Dados | Leitura e Escrita na Raw e Bronze | Implementar e manter pipelines de ingest√£o e transforma√ß√£o.     |
| Cientista de Dados  | Leitura na Silver e Gold          | Realizar an√°lises e modelagem preditiva sobre dados confi√°veis. |
| Analista de Dados   | Leitura na Gold                   | Construir dashboards e relat√≥rios para tomada de decis√£o.       |
| Administrador       | Controle Total                    | Gerenciar usu√°rios, permiss√µes e monitorar seguran√ßa.           |

- Todos os acessos s√£o concedidos seguindo o princ√≠pio do **menor privil√©gio**.  
- O controle √© feito via **RBAC** da Azure Storage Account e Service Principals.   

#### Azure Storage Account (RBAC)

- Engenheiros de dados recebem Storage Blob Data Contributor nos containers Raw e Bronze.
- Cientistas e analistas recebem Storage Blob Data Reader ou Reader parcial nos containers Silver e Gold.

#### Databricks

- Engenheiros de dados configuram e executam os jobs que processam os dados entre os layers (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold).
- Cientistas de dados podem acessar resultados processados nos jobs em Silver e Gold.
- Analistas de dados podem executar queries e montar dashboards apenas sobre os dados Gold gerados pelos jobs.
- Administradores t√™m controle total sobre a Storage Account e podem gerenciar jobs, permiss√µes e auditoria no Databricks.

#### Unity Catalog

- O Unity Catalog gerencia tabelas, views, esquemas e fun√ß√µes, garantindo controle de acesso, incluindo permiss√µes em n√≠vel de objeto, linha e coluna.
- **Rastreamento e auditoria**: permite registrar data lineage completo, hist√≥rico de altera√ß√µes e acessos aos dados.
- **Democratiza√ß√£o de dados**: usu√°rios podem descobrir e acessar dados de forma segura sem depender de pipelines espec√≠ficos ou da interven√ß√£o de engenheiros de dados.
- **Compartilhamento seguro de dados**: tabelas e views podem ser compartilhadas entre diferentes equipes, unidades de neg√≥cio ou at√© parceiros externos, mantendo o controle sobre quem pode visualizar ou alterar os dados.
- **Padroniza√ß√£o e organiza√ß√£o**: centraliza metadados, schemas e nomenclaturas, garantindo consist√™ncia em todo o Data Lake e em m√∫ltiplas camadas de processamento.

### 3.12 Observabilidade e Monitoramento

O projeto adota logs como principal mecanismo de monitoramento para acompanhar a execu√ß√£o dos pipelines e detectar falhas, garantindo rastreabilidade e confiabilidade nos fluxos de dados.

#### Logs e M√©tricas
- **Microservi√ßos (AKS)**: gera√ß√£o de logs de execu√ß√£o e falhas.
- **Databricks Jobs**: registro autom√°tico de logs de execu√ß√£o, status de tarefas e m√©tricas de processamento.  
- **GitHub Actions**: logs de cada etapa de CI/CD, permitindo auditoria das execu√ß√µes.

### 3.13 Escalabilidade e Desempenho

O projeto foi estruturado para suportar aumento de volume de dados e crescimento no n√∫mero de fontes, mantendo efici√™ncia e confiabilidade no processamento.

#### Escalabilidade
- **Microservi√ßos em AKS**: permitem escalar horizontalmente, aumentando ou reduzindo r√©plicas conforme a demanda de ingest√£o.  
- **Databricks**: os jobs utilizam clusters com autoscale configurado, que realizam escalabilidade horizontal, adicionando ou removendo n√≥s automaticamente conforme o volume de dados processado.
- **Storage Account**: arquitetura baseada em containers independentes para cada camada de dados, possibilitando expans√£o sem necessidade de reestrutura√ß√£o.

#### Desempenho
- **Delta Lake**: garante performance em consultas e manipula√ß√£o de grandes volumes de dados por meio de otimiza√ß√µes internas (indexa√ß√£o, caching e compacta√ß√£o de arquivos).  
- **Auto Loader**: possibilita ingest√£o cont√≠nua e eficiente dos dados da Raw para a Bronze, reduzindo o tempo de lat√™ncia.  
- **Transforma√ß√µes distribu√≠das no Databricks**: uso de processamento paralelo para melhorar a velocidade em opera√ß√µes de limpeza e padroniza√ß√£o.

#### Par√¢metros de Performance e Efici√™ncia do Cluster Databricks 

O cluster Databricks est√° configurado com par√¢metros de otimiza√ß√£o para melhorar a performance de escrita e leitura de dados em tabelas Delta:  

- `spark.databricks.delta.optimizeWrite.enabled = true` ‚Üí reduz o n√∫mero de pequenos arquivos gerados, consolidando-os automaticamente durante a escrita.  
- `spark.databricks.delta.autoCompact.enabled = true` ‚Üí combina arquivos pequenos em arquivos maiores de forma cont√≠nua, melhorando a performance de leitura e queries anal√≠ticas.
- `spark.databricks.delta.schema.autoMerge.enabled = true` ‚Üí Permite que o Delta Lake atualize automaticamente o schema de uma tabela durante opera√ß√µes de merge, append ou overwrite, sem necessidade de recria√ß√£o manual.
- `spark.sql.adaptive.enabled = true` ‚Üí Ativa o Adaptive Query Execution, recurso do Spark que ajusta dinamicamente o plano de execu√ß√£o em tempo de execu√ß√£o (por exemplo, alterando o n√∫mero de parti√ß√µes ou aplicando broadcast joins quando vantajoso), melhorando desempenho de forma autom√°tica.
- `spark.databricks.adaptive.autoOptimizeShuffle = true` ‚Üí Faz parte do AQE e permite que o Databricks reajuste dinamicamente a estrat√©gia de shuffle, otimizando a distribui√ß√£o de dados entre os executores para evitar skew (desequil√≠brio de carga entre parti√ß√µes).
- `spark.sql.adaptive.coalescePartitions.enabled = true` ‚Üí Habilita o ajuste autom√°tico de parti√ß√µes ap√≥s o shuffle, reduzindo o n√∫mero de parti√ß√µes pequenas e otimizando o uso de recursos ao evitar a cria√ß√£o de tarefas muito pequenas (task overhead).
- `spark.databricks.io.cache.enabled = true` ‚Üí Ativa o Databricks I/O Cache, que armazena dados frequentemente acessados em disco local SSD do cluster, reduzindo o tempo de leitura e o custo de reprocessamento em consultas repetitivas.

**Benef√≠cios principais**:  
- Capacidade de lidar com aumento no volume e variedade de dados.  
- Redu√ß√£o da lat√™ncia entre ingest√£o e disponibiliza√ß√£o dos dados anal√≠ticos.  
- Otimiza√ß√£o de custos ao escalar recursos somente quando necess√°rio.

### 3.14 Metodologia de Desenvolvimento

O ciclo de desenvolvimento do projeto segue a estrat√©gia de **GitFlow** para organiza√ß√£o e rastreabilidade do c√≥digo.  

Principais pr√°ticas adotadas:
- **Branch main** ‚Üí sempre est√°vel, representa a vers√£o de produ√ß√£o.  
- **Branch develop** ‚Üí concentra as novas features e integra√ß√µes em andamento.  
- **Feature branches** ‚Üí criadas a partir de `develop` para desenvolvimento de funcionalidades espec√≠ficas.  
- **Release branches** ‚Üí usadas para preparar vers√µes est√°veis antes de ir para produ√ß√£o.  
- **Hotfix branches** ‚Üí permitem corre√ß√µes r√°pidas diretamente na `main`.

   ![Figura 1 ‚Äî Gitflow](assets/images/config-execution/gitflow.png)

---

##  üöÄ 4. Guia de Configura√ß√£o e Execu√ß√£o

### 4.1 Pr√©-requisitos

Antes de configurar e executar o projeto, √© necess√°rio garantir que o ambiente possua os seguintes pr√©-requisitos:

#### 4.1.1 **Service Principal (SPN)** criado previamente

A cria√ß√£o de uma SPN pode ser feita de forma simples de acordo com a documenta√ß√£o da Microsoft: [Cria√ß√£o de SPN](https://learn.microsoft.com/en-us/entra/identity-platform/howto-create-service-principal-portal#register-an-application-with-microsoft-entra-id-and-create-a-service-principal)

#### 4.1.2 **Secret da SPN** configurado (*Secret Value*, n√£o o *Secret ID*)

1. Acesse sua SPN criada anteriormente, buscando ela na barra de pesquisa:

![SPN - 0101](assets/images/pre-configs/spn-01-01.png)

2. No menu a esquerda, selecione *Certificates & secrets*

![SPN - 02](assets/images/pre-configs/spn-01.png)

3. Na aba **Client secrets** selecione **New client secret**, no menu que sera aberto a direita, coloque uma descri√ß√£o e tempo de expira√ß√£o para a secret e selecione **Add**

![SPN - 03](assets/images/pre-configs/spn-02.png)

4. Na proxima aba copie/salve o valor que esta na coluna **Value** (N√£o copie o Secret ID, ele n√£o ser√° usado)

![SPN - 04](assets/images/pre-configs/spn-03.png)

#### 4.1.3 **Permissionamento da SPN**

- A **SPN** precisa ter permiss√µes na assinatura da Azure:  
  - *Contributor*
  - *User Access Administrator*


  1. Na sua subscription, acesse a op√ß√£o: **Access control (IAM)**, no menu a direita clique em **add +** e depois em **Add role assignment**
  
  ![Access Subs - 01](assets/images/pre-configs/access-subs-01.png)

  2. Nas Roles, usa a barra de pesquisa para encontrar a **Contributor** e depois selecione ela no menu **Name**

  ![Access Subs - 02](assets/images/pre-configs/access-subs-02.png)

  3. Na aba Member, selecione a SPN em **+ Select members**, ser√° aberto um menu a direita, ent√£o busque sua SPN e clique em **Select**

  ![Access Subs - 03](assets/images/pre-configs/access-subs-04.png)

  Se tudo estiver certo, sua SPN vai aparecer nos membros

  ![Access Subs - 04](assets/images/pre-configs/access-subs-05.png)

  4. Na aba **Review + assign** verifique a role e a SPN ent√£o clique em **Review + assign**

  ![Access Subs - 05](assets/images/pre-configs/access-subs-06.png)

  5. Agora fa√ßa o mesmo para a role **User Access Administrator**

  ![Access Subs - 06](assets/images/pre-configs/access-subs-03.png)

  Uma observa√ß√£o: para esse acesso, √© necessario marcar a terceira op√ß√£o de acesso na aba **Conditions**

  ![Access Subs - 07](assets/images/pre-configs/access-subs-07.png)

  6. Ap√≥s atribui√ß√£o dos 2 acessos, elas v√£o aparecer na aba de acessos da sua SPN

  ![Access Subs - 08](assets/images/pre-configs/access-subs-08.png)

- A **SPN** precisa ter permiss√µes no servi√ßo Microsoft Graph:  
  - *Application.Read.All*
  - *Group.ReadWrite.All*
  - *User.Read*


  1. No menu da sua SPN, acesse a op√ß√£o **API permissions**

  ![Access API - 01](assets/images/pre-configs/spn-api-01.png)

  2. No centro da pagina, selecione **+ Add a permission**, no menu que ser√° aberto a direita, selecione **Microsoft Graph**

  ![Access API - 02](assets/images/pre-configs/spn-api-02.png)

  3. Agora selecione **Application permissions**, na barra de busca pesquisa **application**, na barra das permiss√µes de application, selecione **Application.Read.All** e **Add permissions**

  ![Access API - 03](assets/images/pre-configs/spn-api-03.png)

  4. Fa√ßa o mesmo para a permiss√£o **Group.ReadWrite.All**

  ![Access API - 04](assets/images/pre-configs/spn-api-04.png)

  5. Ap√≥s as permiss√µes serem adicionadas, selecione o bot√£o **Grant admin consent for Default Directory**

  ![Access API - 05](assets/images/pre-configs/spn-api-05.png)

  6. Ap√≥s isso, as permiss√µes com acesso ao directory estar√£o aplicadas

  ![Access API - 06](assets/images/pre-configs/spn-api-06.png)

#### 4.1.4 **Personal Access Token (PAT)** do GitHub criado. 

Permiss√µes necessarias no Token:

![Token - 01](assets/images/pre-configs/token-01.png)

### **4.2 Cria√ß√£o do Reposit√≥rio a partir do Template**

1. No reposit√≥rio do projeto, acesse **‚ÄúUse this template‚Äù**.
   
   ![Template - 01](assets/images/config-execution/template-01.png)

2. Selecione **‚ÄúCreate a new repository‚Äù**.
   
   ![Template - 02](assets/images/config-execution/template-02.png)

3. Mantenha marcada a op√ß√£o para levar todas as *branches* do reposit√≥rio, defina o nome em **Repository name**, adicione uma descri√ß√£o, configure a visibilidade e clique em **Create repository**.
   
   ![Template - 03](assets/images/config-execution/template-03.png)

4. Aguarde alguns minutos enquanto o reposit√≥rio √© criado.
   
   ![Template - 04](assets/images/config-execution/template-04.png)

---

### **4.3 Configura√ß√£o das Secrets e Vari√°veis de Ambiente**

1. Ap√≥s o reposit√≥rio ser criado, acesse **Settings**.
   
   ![Secrets - 01](assets/images/config-execution/secrets-01.png)

2. No menu √† esquerda, clique em **Secrets and variables**.
   
   ![Secrets - 02](assets/images/config-execution/secrets-02.png)

3. Selecione a op√ß√£o **Actions**.
   
   ![Secrets - 03](assets/images/config-execution/secrets-03.png)

4. Em **Actions secrets and variables**, clique em **New repository secret**.
   
   ![Secrets - 04](assets/images/config-execution/secrets-04.png)

5. A primeira *secret* a ser adicionada ser√° **AZURE_CREDENTIALS**, seguindo o modelo JSON abaixo:
   
   **clientId** -> ID da sua SPN
   
   **clientSecret** -> Secret da sua SPN
   
   **subscriptionId** -> ID da sua Subscription
   
   **tenantId** -> ID do seu tenant
   
   ![Secrets - 05](assets/images/config-execution/secrets-05.png)

6. Em seguida, cadastre o token do GitHub com o nome **GH_PAT_TOKEN**.
   
   ![Secrets - 06](assets/images/config-execution/secrets-06.png)

7. Cadastre a chave para acessar a API, chamada **API_KEY**.

   Observa√ß√£o: Utilize o mesmo valor da imagem -> 8af74270
   
   ![Secrets - 07](assets/images/config-execution/secrets-07.png)

8. Cadastre a chave para acessar o banco de dados, chamada **DB_KEY**.

   Observa√ß√£o: Utilze o mesmo valor da imagem -> npg_Q94FurniGUlq
   
   ![Secrets - 08](assets/images/config-execution/secrets-08.png)

9. Ao finalizar, o painel de *secrets* deve se parecer com este:
   
   ![Secrets - 09](assets/images/config-execution/secrets-09.png)

---

### **4.4 Provisionamento da Infraestrutura na Azure**

1. Com tudo configurado, acesse a aba **Actions** no topo do reposit√≥rio.
    
    ![Figura 1 ‚Äî Infra](assets/images/config-execution/infra-01.png)

2. No menu √† esquerda, selecione o workflow **Deploy Cloud Infrastructure**.
    
    ![Figura 2 ‚Äî Infra](assets/images/config-execution/infra-02.png)

3. Clique em **Run workflow** e confirme.
    
    ![Figura 3 ‚Äî Infra](assets/images/config-execution/infra-03.png)

4. Ap√≥s a execu√ß√£o completa, o workflow deve aparecer com todos os *steps* conclu√≠dos.
    
    ![Figura 4 ‚Äî Infra](assets/images/config-execution/infra-04.png)

   No Summary √© possivel acompanhar um resumo dos recursos que foram criados

    ![Figura 4.2 ‚Äî Infra](assets/images/config-execution/infra-04-02.png)

5. Verifique na sua conta Azure os **Resource Groups** criados: um para os recursos principais, outro para os recursos base do AKS e outro para os recursos base do Databricks.
    
    ![Figura 5 ‚Äî Infra](assets/images/config-execution/infra-05.png)

6. O **Resource Group principal** conter√° os recursos criados pelo workflow, incluindo **Databricks, AKS, ACR, Storage Account e Metastore Connector**.
    
    ![Figura 6 ‚Äî Infra](assets/images/config-execution/infra-06.png)

---

### **4.5 Build e Publica√ß√£o das Imagens Docker**

1. Com a infraestrutura pronta, acesse os workflows e selecione **Build and Push to ACR**.
    
    ![Figura 1 ‚Äî ACR](assets/images/config-execution/acr-01.png)

2. No menu √† direita, selecione as op√ß√µes de **Run workflow**.
    
    ![Figura 2 ‚Äî ACR](assets/images/config-execution/acr-02.png)

3. Ap√≥s a execu√ß√£o completa, o workflow deve aparecer com todos os *steps* conclu√≠dos.
    
    ![Figura 3 ‚Äî ACR](assets/images/config-execution/acr-02-02.png)

   No Summary √© possivel acompanhar um resumo das imagens e vers√µes que foram enviadas ao ACR

    ![Figura 3.2 ‚Äî ACR](assets/images/config-execution/acr-02-03.png)

4. Verifique no **Azure Container Registry (ACR)** os reposit√≥rios e vers√µes criadas dos microservi√ßos.
    
    ![Figura 4 ‚Äî ACR](assets/images/config-execution/acr-03.png)

---

### **4.6 Deploy dos Microservi√ßos no AKS**

1. Ap√≥s o workflow do ACR, o workflow do **AKS** √© disparado automaticamente.
    
    ![Figura 1 ‚Äî AKS](assets/images/config-execution/aks-01.png)

2. Acompanhe no **summary** as vers√µes dos microservi√ßos que est√£o sendo implantadas.
    
    ![Figura 2 ‚Äî AKS](assets/images/config-execution/aks-02.png)

3. Verifique no **AKS** se os microservi√ßos est√£o instalados.
    
    ![Figura 3 ‚Äî AKS](assets/images/config-execution/aks-03.png)

---

### **4.7 Execu√ß√£o do Pipeline de Dados**

1. Com tudo instalado, execute o pipeline de ingest√£o e transforma√ß√£o de dados, selecionando o workflow **Orchestrate Data Pipeline**.
    
    ![Figura 1 ‚Äî Pipeline](assets/images/config-execution/pipe-01.png)

2. Clique em **Run workflow**.
    
    ![Figura 2 ‚Äî Pipeline](assets/images/config-execution/pipe-02.png)

3. Ap√≥s a execu√ß√£o, verifique no **AKS** se os jobs foram conclu√≠dos com sucesso.
    
    ![Figura 3 ‚Äî Pipeline](assets/images/config-execution/pipe-03.png)

4. Se acompanharmos no Storage Account, no container Raw, poderemos ver as pastas e dados referentes a cada uma das fontes de dados (File, Database e API)

    ![Figura 1 ‚Äî Storage](assets/images/config-execution/storage-01.png)

    ![Figura 2 ‚Äî Storage](assets/images/config-execution/storage-02.png)

    ![Figura 3 ‚Äî Storage](assets/images/config-execution/storage-03.png)

    ![Figura 4 ‚Äî Storage](assets/images/config-execution/storage-04.png)

5. Confirme no **Databricks** a execu√ß√£o do job de transforma√ß√£o.
    
    ![Figura 4 ‚Äî Pipeline](assets/images/config-execution/pipe-04.png)

6. Podemos verificar no nosso catalogo de dados no Databricks, que as tabelas bronze, silver e gold estar√£o criadas

    ![Figura 1 ‚Äî Catalog](assets/images/config-execution/catalog-01.png)

7. No Storage Account tamb√©m temos a informa√ß√£o dos dados repousados, cada um em seu container especifico

    ![Figura 5 ‚Äî Storage](assets/images/config-execution/storage-05.png)

    ![Figura 6 ‚Äî Storage](assets/images/config-execution/storage-06.png)

    ![Figura 7 ‚Äî Storage](assets/images/config-execution/storage-07.png)

8. A tabela bronze vir√° com os dados X de forma Y

    ![Figura 1 ‚Äî Table](assets/images/config-execution/table-01.png)

9. A tabela silver de forma Z

    ![Figura 2 ‚Äî Table](assets/images/config-execution/table-02.png)

10. A tabela gold de forma XYZ

    ![Figura 3 ‚Äî Table](assets/images/config-execution/table-03.png)

### **4.8 Desenvolvimento e Atualiza√ß√£o de Microservi√ßos de ingest√£o**

### **4.9 Desenvolvimento e Atualiza√ß√£o de Microservi√ßos de Data Processing**

---

##  üí° 5. Melhorias e Considera√ß√µes Finais

###  5.1 Melhorias Futuras

- **Seguran√ßa de Rede (VNet e Private Endpoints):** inclus√£o de Virtual Networks e Private Endpoints para isolar os recursos da Azure e garantir maior seguran√ßa no tr√°fego de dados. 
- **Fluxo de Ambientes (Dev / Pre / Prod):** implementa√ß√£o de m√∫ltiplos ambientes com pipelines de deploy independentes, possibilitando testes e valida√ß√µes antes de subir em produ√ß√£o.    
- **Observabilidade e Alertas:** centralizar m√©tricas, logs e alertas em ferramentas como **Azure Monitor** ou **Grafana**, possibilitando detec√ß√£o proativa de falhas. 
- **Infraestrutura como C√≥digo Din√¢mica:** permitir que a pr√≥pria GitHub Action altere a infraestrutura via Terraform ou equivalente, utilizando um backend para salvar estado.
- **Sincroniza√ß√£o de Grupos AD e Databricks:** automatizar a sincroniza√ß√£o de grupos do Azure AD com os grupos de Databricks, reduzindo etapas manuais de configura√ß√£o de permiss√µes e acesso.
- **Contratos de Dados:** ado√ß√£o de contratos de dados para permitir ingest√£o de m√∫ltiplos tipos de schemas.
- **Pipelines Version√°veis e End-to-End:** possibilitar desenvolvimento de m√∫ltiplos pipelines version√°veis, desacoplados do Terraform fixo, integrados com os contratos de dados, permitindo criar novos fluxos de ingest√£o.
- **Expurgo da Camada Raw** : remover dados da camada Raw ap√≥s a ingest√£o e valida√ß√£o, reduzindo custos de armazenamento.
- **Suporte a Streaming**: estender a arquitetura atual para incluir pipelines de ingest√£o e processamento streaming, tornando a plataforma h√≠brida (batch + streaming) e preparada para casos de uso em tempo real.
- **Abstra√ß√£o Multicloud**: reestruturar a camada de infraestrutura e os microservi√ßos para desacoplar depend√™ncias espec√≠ficas da Azure, viabilizando execu√ß√£o em m√∫ltiplos provedores de nuvem (AWS, GCP, Azure), com conectores e provisionamento agn√≥sticos.
- **Evolu√ß√£o do fluxo de monitoramento**: aprimorar o monitoramento atual, baseado em logs de microservi√ßos, Databricks Jobs e GitHub Actions, centralizando m√©tricas, dashboards e alertas em ferramentas como Azure Monitor ou Grafana.

###  5.2 Considera√ß√µes Finais

O projeto demonstrou como √© poss√≠vel integrar dados de m√∫ltiplas fontes e formatos, organizando-os em um pipeline escal√°vel e confi√°vel na Azure.  
A solu√ß√£o aplicou boas pr√°ticas de engenharia de dados (arquitetura medalh√£o, uso de Delta Lake, pipelines automatizados) em conjunto com boas pr√°ticas de engenharia de software (microservi√ßos, CI/CD, IaC).  

Ao longo do desenvolvimento, foi poss√≠vel explorar tecnologias como Terraform, Azure, AKS, Databricks, Delta Lake e GitHub Actions, refor√ßando a import√¢ncia da Infraestrutura como C√≥digo, da modulariza√ß√£o de microservi√ßos e da observabilidade ponta a ponta no ciclo de vida dos dados.

Esses elementos resultaram em uma solu√ß√£o orientada √† automa√ß√£o ‚Äî capaz de sustentar fluxos de dados com seguran√ßa, rastreabilidade e efici√™ncia. Al√©m de validar conceitos t√©cnicos, o projeto tamb√©m proporcionou uma vis√£o integrada sobre o papel estrat√©gico da engenharia de dados na constru√ß√£o de plataformas anal√≠ticas e escal√°veis.

---

## üìö 6. Refer√™ncias

### **Infraestrutura e Cloud**

* [Microsoft Azure Documentation]() ‚Äî Storage Account, AKS, ACR, RBAC, Service Principals, Managed Identities
* [Terraform Azure Provider](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs) ‚Äî configura√ß√£o e boas pr√°ticas
* [Unity Catalog (Databricks)](https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/) ‚Äî governan√ßa e lineage de dados
* [Azure Databricks Architecture Overview](https://learn.microsoft.com/en-us/azure/databricks/getting-started/high-level-architecture) ‚Äî arquitetura e pr√°ticas recomendadas

---

### **Engenharia de Dados**

* [Arquitetura Medalh√£o (Medallion Architecture)](https://www.databricks.com/glossary/medallion-architecture) ‚Äî boas pr√°ticas e camadas de dados
* [Delta Lake](https://learn.microsoft.com/en-us/azure/databricks/delta/) ‚Äî fundamentos ACID e otimiza√ß√£o de performance
* [Auto Loader (Databricks)](https://learn.microsoft.com/en-us/azure/databricks/ingestion/cloud-object-storage/auto-loader/) ‚Äî ingest√£o incremental
* [Data Quality Framework](https://www.montecarlodata.com/blog-pyspark-data-quality-checks) ‚Äî PySpark validations
* [Mascaramento e Anonimiza√ß√£o de Dados](https://www.totvs.com/blog/negocios/anonimizacao/) ‚Äî princ√≠pios LGPD / GDPR

---

### **Engenharia de Software**

* [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html) ‚Äî princ√≠pios de arquitetura limpa (Robert C. Martin)
* [Python Best Practices](https://peps.python.org/pep-0008/) ‚Äî PEP8
* [GitFlow Workflow](https://www.alura.com.br/artigos/git-flow-o-que-e-como-quando-utilizar) ‚Äî versionamento e integra√ß√£o cont√≠nua
* [Testes Automatizados em Python](https://medium.com/@habbema/testes-seu-scripts-python-com-pytest-c08638423ba9) ‚Äî pytest, mocks e CI
* [Linting e Pre-Commit Hooks](https://pre-commit.com/) ‚Äî padroniza√ß√£o de c√≥digo
* [Docker e Helm Charts](https://medium.com/@max.difranco/level-up-your-deployments-with-helm-docker-and-kubernetes-5f3f8982fa6a) ‚Äî empacotamento e deploy

---

### **Automa√ß√£o e CI/CD**

* [GitHub Actions Documentation](https://github.com/features/actions?locale=pt-BR) ‚Äî workflows, secrets e pipelines

---

### **Observabilidade, Seguran√ßa e Governan√ßa**

* [Databricks Job Monitoring](https://learn.microsoft.com/en-us/azure/databricks/jobs/monitor) ‚Äî logs e auditoria
* [Unity Catalog (Databricks)](https://www.databricks.com/blog/unity-catalog-governance-action-monitoring-reporting-and-lineage) ‚Äî data lineage e cataloga√ß√£o de dados

---

### **Metodologias e Boas Pr√°ticas**

* [DataOps](https://blog.dsacademy.com.br/o-que-e_dataops/) ‚Äî automa√ß√£o, versionamento e governan√ßa
* [DevOps para Engenharia de Dados (Data DevOps)](https://www.xenonstack.com/insights/devops-best-practices-for-data-engineers) ‚Äî integra√ß√£o e entrega cont√≠nua

---
